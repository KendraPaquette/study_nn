{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "\n",
    "This source code is licensed under the CC BY-NC license found in the\n",
    "LICENSE.md file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from munch import Munch\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ema.csv', sep=',')\n",
    "df = df.sort_values(['subid', 'dttm_obs'])[['dttm_obs', 'subid', 'ema_1', 'ema_2', 'ema_3', 'ema_4', \\\n",
    "                                            'ema_5', 'ema_6', 'ema_7', 'ema_8', 'ema_9', 'ema_10']]\n",
    "\n",
    "# Handling NA: drop the entire row if 4th entry is NA \n",
    "# For morning-only survey, set dummy=1 if survey reported, otherwise dummy=0\n",
    "df = df.fillna(-6.0)\n",
    "df = df[df['ema_4'] > -1]\n",
    "df['ema_dummy'] = (df['ema_8'] > -1)\n",
    "df.loc[df['ema_8'] < 0, ['ema_8', 'ema_9', 'ema_10']] = 0\n",
    "\n",
    "# Encoding: 'Yes/No -> 0/1'\n",
    "df = df.replace('No',0)\n",
    "df = df.replace('Yes',1)\n",
    "\n",
    "# Date-time encoding -- in hour unit \n",
    "df['date'] = (pd.to_datetime(df['dttm_obs']).astype('int64') // (10**9)) / 3600\n",
    "df2 = df[['subid', 'ema_1', 'ema_2', 'ema_3', 'ema_4', \\\n",
    "            'ema_5', 'ema_6', 'ema_7', 'ema_8', 'ema_9', 'ema_10', 'ema_dummy', 'date']]\n",
    "\n",
    "\n",
    "time_df = pd.read_csv('labels_1day.csv', sep=',')\n",
    "time_df = time_df.sort_values(['subid', 'dttm_label']) \n",
    "time_df['date'] = (pd.to_datetime(time_df['dttm_label']).astype('int64') // (10**9)) / 3600\n",
    "time_df = time_df.replace('no',0)\n",
    "time_df = time_df.replace('yes',1)\n",
    "\n",
    "time_df = time_df[['subid', 'lapse', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7b76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63457b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(org_data, time_label):\n",
    "    # 24hr window right-index\n",
    "    fj = 0    \n",
    "    \n",
    "    # offset starting date-time to 0 \n",
    "    offset_time = time_label[0,-1] + 0.0\n",
    "    org_data[:,-1] -= offset_time\n",
    "    time_label[:,-1] -= offset_time\n",
    "\n",
    "    dataset = []\n",
    "    tq = ts = 0\n",
    "    while(tq < time_label.shape[0] and ts < org_data.shape[0] ):\n",
    "        if(ts == org_data.shape[0] or (tq < time_label.shape[0] and time_label[tq, -1] < org_data[ts, -1])):\n",
    "            y = 1 if( time_label[tq,1] > 0 ) else 0\n",
    "            dataset.append({'type':'query', 'out': y, 'time': time_label[tq,-1]})\n",
    "            \n",
    "            while(tq < time_label.shape[0] and time_label[tq,-1] < org_data[ts,-1] ):\n",
    "                tq += 1\n",
    "        else:\n",
    "            dataset.append({'type':'survey', 'obs': org_data[ts, 1:]+0.0, 'time': org_data[ts,-1]})\n",
    "            ts += 1\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cc443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def input_xgboost_data(org_data, time_label):\n",
    "    j = [0,0,0,0,0]\n",
    "    fj = 0\n",
    "    window = [12, 24, 48, 72, 168]\n",
    "    \n",
    "    dataset = []\n",
    "    tq = ts = 0\n",
    "\n",
    "    while( tq < time_label.shape[0] ):\n",
    "        time = time_label[tq,-1]\n",
    "\n",
    "        while( ts < org_data.shape[0] and org_data[ts,-1] < time ):\n",
    "            ts += 1\n",
    "        \n",
    "        for k in range(5):\n",
    "            while( j[k] < ts-1 and org_data[j[k], -1] < time - window[k] ):\n",
    "                j[k] = j[k] + 1\n",
    "                   \n",
    "        if( ts == 0 ):\n",
    "            tq += 1\n",
    "            continue\n",
    "            \n",
    "        X1 = np.concatenate(([np.mean(org_data[j[k]:ts, 1:], axis=0) for k in range(5)], \\\n",
    "                            [np.min(org_data[j[k]:ts, 1:], axis=0) for k in range(5)] , \\\n",
    "                            [np.max(org_data[j[k]:ts, 1:], axis=0) for k in range(5)]), axis=1)\n",
    "        X1 = np.concatenate(X1)\n",
    "\n",
    "        sub_mean = np.mean(org_data[:ts], axis=0)\n",
    "        X = np.concatenate((X1, sub_mean[1:]))\n",
    "        X = np.concatenate((X, org_data[ts-1, 1:]))\n",
    "\n",
    "        y = 1 if (time_label[tq,1] > 0 ) else 0\n",
    "        tq += 1\n",
    "        \n",
    "        dataset.append({'in':X, 'out':y})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def xgboost_main(train_index, test_index):\n",
    "    trainset = []\n",
    "    for m in train_index:\n",
    "        subid = subid_list[m] + 1\n",
    "        sub_data = raw_data[raw_data[:,0] == subid] \n",
    "        time_label = time_raw_data[time_raw_data[:,0]==subid]                \n",
    "        trainset.extend(input_xgboost_data(sub_data, time_label))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=500000, shuffle=True, drop_last=False)\n",
    "\n",
    "    testset = []\n",
    "    for m in test_index:\n",
    "        subid = subid_list[m] + 1\n",
    "        sub_data = raw_data[raw_data[:,0] == subid]     \n",
    "        time_label = time_raw_data[time_raw_data[:,0]==subid]                \n",
    "        testset.extend(input_xgboost_data(sub_data, time_label))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=60000, shuffle=False, drop_last=False)\n",
    "\n",
    "    data_iter = iter(train_loader)\n",
    "    train_data = next(data_iter)\n",
    "    X = train_data['in']\n",
    "    y = train_data['out']\n",
    "\n",
    "    test_iter = iter(test_loader)\n",
    "    test_data = next(test_iter)\n",
    "\n",
    "    # Create regression matrices\n",
    "    dtrain_reg = xgb.DMatrix(X, y)\n",
    "\n",
    "    X_test = test_data['in']\n",
    "    y_test = test_data['out']\n",
    "    dtest_reg = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "    params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\", \"device\": \"cuda\"}\n",
    "\n",
    "    print(X.shape, X_test.shape)\n",
    "    \n",
    "    n = 10\n",
    "    xgmodel = xgb.train(\n",
    "       params=params,\n",
    "       dtrain=dtrain_reg,\n",
    "       num_boost_round=n,\n",
    "    )\n",
    "\n",
    "    preds = xgmodel.predict(dtest_reg)\n",
    "    print(len(y_test[y_test>0]), len(preds[preds>0.1]), len(preds))\n",
    "    print('XgBoost: AUC = %.2f' % roc_auc_score(y_test, preds))  #1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = df2.values.astype(np.float32)\n",
    "time_raw_data = time_df.values.astype(np.float32)\n",
    "\n",
    "# action encoding: \n",
    "# 0 - no survey, predict No\n",
    "# 1 - yes survey, predict No\n",
    "# 2 - no survey, predict Yes\n",
    "# 3 - yes survey, predict Yes\n",
    "action_max = 4\n",
    "\n",
    "# feature encoding\n",
    "# 0 - no lapse within 24hr\n",
    "# 1 - yes lapse within 24hr\n",
    "feature_max = 2\n",
    "\n",
    "state_dim, embed_dim, feature_dim = 12, 256, 1\n",
    "env_list, subid_list = [], []\n",
    "for subid in range(270):\n",
    "    sub_data = raw_data[raw_data[:,0]==(subid+1)]\n",
    "    time_label = time_raw_data[time_raw_data[:,0]==(subid+1)]\n",
    "    if( len(sub_data) == 0 or len(time_label) == 0 ):\n",
    "        continue\n",
    "          \n",
    "    subid_list.append(subid)\n",
    "    env_list.append(input_data(sub_data, time_label))\n",
    "\n",
    "print(len(subid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e88104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39658178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb11780",
   "metadata": {},
   "source": [
    "# Retrieve Saved Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9691a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env, VecEnv\n",
    "\n",
    "num_process = 50\n",
    "window_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(venv, model, agent, mode='policy'):\n",
    "    scatter = []\n",
    "    num_process = len(venv.test_ids)\n",
    "    \n",
    "    cnt, n_measure, n_hit = [0 for i in range(num_process)], [0 for i in range(num_process)], [0 for i in range(num_process)]\n",
    "    y, outy = [], []\n",
    "\n",
    "    env = venv.venv[0]\n",
    "    obs, info = venv.reset(mode='test')\n",
    "    cumr = 0\n",
    "    \n",
    "    ts = torch.zeros(num_process, window_size, env.state_dim).to(device)\n",
    "    ta = torch.zeros(num_process, window_size, env.action_dim).to(int).to(device)\n",
    "\n",
    "    bf = model(ts, ta, output_embedding=True)\n",
    "    bf = bf.detach()\n",
    "\n",
    "    for t in range(1000):\n",
    "        if( mode == 'policy' ):\n",
    "            actions, _, _ = agent.select_action(bf)\n",
    "            actions = actions.detach().cpu()\n",
    "        else:\n",
    "            actions = torch.zeros(num_process, env.action_dim).to(int) + 1\n",
    "\n",
    "        obs, rewards, dones, infos = venv.step(actions)\n",
    "        cumr += sum(rewards)\n",
    "        \n",
    "        predict_features = model.predict_forward(bf).detach()       \n",
    "   \n",
    "        # add transition data to dataset\n",
    "        all_done = True\n",
    "        for i in range(num_process):\n",
    "            if( infos[i] == -1 ):\n",
    "                continue\n",
    "\n",
    "            all_done = False\n",
    "            if (infos[i] != 'survey'):\n",
    "                check_y = nn.Softmax(dim=-1)(predict_features[i]).reshape(feature_max).detach().cpu()                \n",
    "                \n",
    "                y.append(infos[i])\n",
    "                outy.append(check_y[1])\n",
    "            \n",
    "                ts[i][-1, -1] = obs[i, -1]\n",
    "            else:    \n",
    "                ts[i] = torch.cat([ts[i][1:,:], obs[i].view(-1, env.state_dim).to(device)], dim=0)\n",
    "                ta[i] = torch.cat([ta[i][1:,:], actions[i].view(-1, 1).to(device)], dim=0)\n",
    "\n",
    "                cnt[i] += 1\n",
    "                if( actions[i] % 2 == 1 ):\n",
    "                    n_measure[i] += 1\n",
    "                if( obs[i,0] > 0 ):\n",
    "                    n_hit[i] += 1\n",
    "\n",
    "        if( all_done ): \n",
    "            break\n",
    "                \n",
    "        bf = model(ts.reshape(num_process,-1,state_dim), ta.reshape(num_process,-1, 1), output_embedding=True).detach()\n",
    "\n",
    "    for i in range(num_process):\n",
    "        scatter.append([n_measure[i]/cnt[i], n_hit[i]/cnt[i]])\n",
    "        print(venv.test_ids[i], ':', n_measure[i], n_hit[i], cnt[i])\n",
    "    \n",
    "    scatter = np.array(scatter)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(4, 3))  \n",
    "\n",
    "    plt.scatter(scatter[:,1], scatter[:,0])\n",
    "    plt.xlabel(\"Average Lapse Count\")\n",
    "    plt.ylabel(\"Survey Ratio\")\n",
    "    plt.show()\n",
    "\n",
    "    print('Average Survey Ratio:', np.mean(scatter[:,0]))\n",
    "\n",
    "    import xgboost as xgb\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    auc_score = roc_auc_score(y, outy)\n",
    "    print('AUC = %.2f' % roc_auc_score(y, outy))  #1\n",
    "\n",
    "    return venv.test_ids, n_measure, n_hit, cnt, auc_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0e397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from SACD import init_SACD_agent\n",
    "from model import build_model\n",
    "from buffer import ReplayBuffer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "for run_id in [1,2,3]:\n",
    "    for penalty in [-1, 0.02, 0.05, 0.08, 0.12]:\n",
    "        out_filename = f\"freq_data_{run_id}_{penalty}.csv\"        \n",
    "        \n",
    "        with open(out_filename, 'w', newline='') as fp:\n",
    "            writer = csv.writer(fp)\n",
    "            writer.writerow([\"id\", \"revealed\", \"lapses\", \"replied\", \"AUC\"])\n",
    "            \n",
    "            for kfold in range(10):\n",
    "                filename = os.path.join(f\"./results/run_{run_id}/\", f\"run_{run_id}_kfold_{kfold}_penalty_{penalty}.pt\")\n",
    "                loaded_data = torch.load(filename, map_location=device) \n",
    "\n",
    "                test_index = loaded_data['test_ids']\n",
    "                train_index = list(set(range(151)) - set(test_index))\n",
    "                # xgboost_main(train_index, test_index)\n",
    "\n",
    "                venv = VecEnv(env_list, train_index, test_index)\n",
    "                env = venv.venv[0]\n",
    "                model = build_model(embed_dim, feature_dim, feature_max, model_family='gpt2').to(device)\n",
    "                agent = init_SACD_agent(env, device, belief_dim=embed_dim, summary_model=model, \\\n",
    "                                        lr_actor=1e-4, lr_critic=2e-4, lr_summary=3e-5, entropy_regularizer=0.03)\n",
    "\n",
    "                model_dict = loaded_data['model_state_dict']  # rm_orig_mod(state[\"model_state_dict\"])\n",
    "                agent_dict = loaded_data['agent_state_dict']\n",
    "\n",
    "                model.load_state_dict(model_dict)\n",
    "                agent.load_dict(agent_dict)\n",
    "\n",
    "                mode = 'full' if( penalty == -1 ) else 'policy'\n",
    "                test_id, n_measure, n_hit, cnt, auc_score = test(venv, model, agent, mode=mode)\n",
    "\n",
    "                for i in range(len(test_id)):\n",
    "                    c = auc_score if ( i == 0 ) else 0\n",
    "                    writer.writerow([test_id[i], n_measure[i], n_hit[i], cnt[i], c])\n",
    "\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9bf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
