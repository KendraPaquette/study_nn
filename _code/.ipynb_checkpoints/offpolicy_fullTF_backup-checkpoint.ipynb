{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109a2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b86bb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "\n",
    "This source code is licensed under the CC BY-NC license found in the\n",
    "LICENSE.md file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from munch import Munch\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d720ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ema.csv', sep=',')\n",
    "df = df.sort_values(['subid', 'dttm_obs'])[['dttm_obs', 'subid', 'ema_1', 'ema_2', 'ema_3', 'ema_4', \\\n",
    "                                            'ema_5', 'ema_6', 'ema_7', 'ema_8', 'ema_9', 'ema_10']]\n",
    "\n",
    "# Handling NA: drop the entire row if 4th entry is NA \n",
    "# For morning-only survey, set dummy=1 if survey reported, otherwise dummy=0\n",
    "df = df.fillna(-6.0)\n",
    "df = df[df['ema_4'] > -1]\n",
    "df['ema_dummy'] = (df['ema_8'] > -1)\n",
    "df.loc[df['ema_8'] < 0, ['ema_8', 'ema_9', 'ema_10']] = 0\n",
    "\n",
    "# Encoding: 'Yes/No -> 0/1'\n",
    "df = df.replace('No',0)\n",
    "df = df.replace('Yes',1)\n",
    "\n",
    "# Date-time encoding -- in hour unit \n",
    "df['date'] = (pd.to_datetime(df['dttm_obs']).astype('int64') // (10**9)) / 3600\n",
    "df2 = df[['subid', 'ema_1', 'ema_2', 'ema_3', 'ema_4', \\\n",
    "            'ema_5', 'ema_6', 'ema_7', 'ema_8', 'ema_9', 'ema_10', 'ema_dummy', 'date']]\n",
    "\n",
    "\n",
    "time_df = pd.read_csv('labels_1day.csv', sep=',')\n",
    "time_df = time_df.sort_values(['subid', 'dttm_label']) \n",
    "time_df['date'] = (pd.to_datetime(time_df['dttm_label']).astype('int64') // (10**9)) / 3600\n",
    "time_df = time_df.replace('no',0)\n",
    "time_df = time_df.replace('yes',1)\n",
    "\n",
    "time_df = time_df[['subid', 'lapse', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7b76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63457b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(org_data, time_label):\n",
    "    # 24hr window right-index\n",
    "    fj = 0    \n",
    "    \n",
    "    # offset starting date-time to 0 \n",
    "    offset_time = org_data[0,-1] + 0.0\n",
    "    org_data[:,-1] -= offset_time\n",
    "    time_label[:,-1] -= offset_time\n",
    "    feature = np.median(org_data[:, 1:-5], axis=0)\n",
    "    \n",
    "    # print(feature.shape)\n",
    "    dataset = []\n",
    "    tq = ts = 0\n",
    "    while(tq < time_label.shape[0] and ts < org_data.shape[0] ):\n",
    "        t_feature = np.concatenate([feature, np.median(org_data[ts:, 1:-5], axis=0)])\n",
    "        \n",
    "        if(ts == org_data.shape[0] or (tq < time_label.shape[0] and time_label[tq, -1] < org_data[ts, -1])):\n",
    "            y = 1 if( time_label[tq,1] > 0 ) else 0\n",
    "            dataset.append({'type':'query', 'out': y, 'time': time_label[tq,-1], 'feature': t_feature})\n",
    "            while(tq < time_label.shape[0] and time_label[tq,-1] < org_data[ts,-1] ):\n",
    "                tq += 1\n",
    "        else:\n",
    "            y = 1 if( tq < time_label.shape[0] and time_label[tq,1] > 0 ) else 0\n",
    "            dataset.append({'type':'survey', 'obs': org_data[ts, 1:-1]+0.0, 'time': org_data[ts,-1], \n",
    "                            'out':y, 'feature': t_feature})\n",
    "            ts += 1\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cf9200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 47, 48, 51, 52, 53, 54, 56, 58, 59, 63, 64, 65, 66, 74, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 88, 90, 92, 93, 94, 97, 98, 99, 100, 103, 109, 110, 116, 117, 118, 119, 121, 128, 130, 131, 134, 135, 136, 137, 138, 139, 143, 149, 150, 156, 158, 161, 162, 163, 166, 167, 169, 171, 172, 175, 178, 179, 180, 181, 183, 185, 187, 188, 189, 190, 191, 192, 193, 196, 197, 200, 201, 203, 205, 207, 208, 209, 211, 212, 213, 214, 215, 218, 221, 222, 223, 224, 225, 230, 231, 232, 234, 236, 238, 240, 241, 242, 243, 245, 248, 252, 255, 259, 262, 263, 264, 265, 268, 270]\n"
     ]
    }
   ],
   "source": [
    "raw_data = df2.values.astype(np.float32)\n",
    "time_raw_data = time_df.values.astype(np.float32)\n",
    "\n",
    "env_list, subid_list = [], []\n",
    "print_list = []\n",
    "for subid in range(270):\n",
    "    sub_data = raw_data[raw_data[:,0]==(subid+1)]\n",
    "    time_label = time_raw_data[time_raw_data[:,0]==(subid+1)]\n",
    "    if( len(sub_data) == 0 or len(time_label) == 0 ):\n",
    "        continue\n",
    "          \n",
    "    subid_list.append(subid)\n",
    "    print_list.append(subid+1)\n",
    "    env_list.append(input_data(sub_data, time_label))\n",
    "\n",
    "print(print_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cc443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29658, 187]) torch.Size([7558, 187])\n",
      "420 1619 7558\n",
      "XgBoost: AUC = 0.90\n",
      "tensor(0.2216, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.85\n",
      "---------------------------------------------------\n",
      "torch.Size([29936, 187]) torch.Size([7280, 187])\n",
      "643 1589 7280\n",
      "XgBoost: AUC = 0.86\n",
      "tensor(0.2712, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.81\n",
      "---------------------------------------------------\n",
      "torch.Size([30143, 187]) torch.Size([7073, 187])\n",
      "699 2045 7073\n",
      "XgBoost: AUC = 0.86\n",
      "tensor(0.2087, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.83\n",
      "---------------------------------------------------\n",
      "torch.Size([30012, 187]) torch.Size([7204, 187])\n",
      "693 1777 7204\n",
      "XgBoost: AUC = 0.89\n",
      "tensor(0.2027, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.85\n",
      "---------------------------------------------------\n",
      "torch.Size([29891, 187]) torch.Size([7325, 187])\n",
      "685 1904 7325\n",
      "XgBoost: AUC = 0.87\n",
      "tensor(0.2349, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.78\n",
      "---------------------------------------------------\n",
      "torch.Size([29962, 187]) torch.Size([7254, 187])\n",
      "822 1920 7254\n",
      "XgBoost: AUC = 0.90\n",
      "tensor(0.1758, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.86\n",
      "---------------------------------------------------\n",
      "torch.Size([29547, 187]) torch.Size([7669, 187])\n",
      "642 1556 7669\n",
      "XgBoost: AUC = 0.87\n",
      "tensor(0.2210, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.85\n",
      "---------------------------------------------------\n",
      "torch.Size([29890, 187]) torch.Size([7326, 187])\n",
      "456 1382 7326\n",
      "XgBoost: AUC = 0.84\n",
      "tensor(0.2270, grad_fn=<MeanBackward0>)\n",
      "myFCN: AUC = 0.81\n",
      "---------------------------------------------------\n",
      "torch.Size([29967, 187]) torch.Size([7249, 187])\n",
      "385 1194 7249\n",
      "XgBoost: AUC = 0.83\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def input_xgboost_data(org_data, time_label):\n",
    "    j = [0,0,0,0,0]\n",
    "    fj = 0\n",
    "    window = [12, 24, 48, 72, 168]\n",
    "    \n",
    "    dataset = []\n",
    "    tq = ts = 0\n",
    "\n",
    "    while( ts < org_data.shape[0] ):\n",
    "        while(tq < time_label.shape[0] and time_label[tq,-1] < org_data[ts,-1] ):\n",
    "            tq += 1\n",
    "            \n",
    "        if( tq >= time_label.shape[0] ):\n",
    "            break\n",
    "            \n",
    "        time = time_label[tq,-1]\n",
    "        while( ts < org_data.shape[0] and org_data[ts,-1] <= time ):\n",
    "            ts += 1\n",
    "        \n",
    "        for k in range(5):\n",
    "            while( j[k] < ts-1 and org_data[j[k], -1] < time - window[k] ):\n",
    "                j[k] = j[k] + 1\n",
    "                               \n",
    "        X1 = np.concatenate(([np.mean(org_data[j[k]:ts, 1:], axis=0) for k in range(5)], \\\n",
    "                            [np.min(org_data[j[k]:ts, 1:], axis=0) for k in range(5)] , \\\n",
    "                            [np.max(org_data[j[k]:ts, 1:], axis=0) for k in range(5)]), axis=1)\n",
    "        X1 = np.concatenate(X1)\n",
    "\n",
    "        sub_mean = np.mean(org_data[:ts], axis=0)\n",
    "        X = np.concatenate((X1, sub_mean[1:]))\n",
    "        X = np.concatenate((X, org_data[ts-1, 1:]))\n",
    "\n",
    "        y = 1 if (time_label[tq,1] > 0 ) else 0        \n",
    "        dataset.append({'in':X, 'out':y})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def xgboost_main(train_index, test_index):\n",
    "    trainset = []\n",
    "    for m in train_index:\n",
    "        subid = subid_list[m] + 1\n",
    "        sub_data = raw_data[raw_data[:,0] == subid] \n",
    "        time_label = time_raw_data[time_raw_data[:,0]==subid]                \n",
    "        trainset.extend(input_xgboost_data(sub_data, time_label))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=500000, shuffle=True, drop_last=False)\n",
    "\n",
    "    testset = []\n",
    "    for m in test_index:\n",
    "        subid = subid_list[m] + 1\n",
    "        sub_data = raw_data[raw_data[:,0] == subid]     \n",
    "        time_label = time_raw_data[time_raw_data[:,0]==subid]                \n",
    "        testset.extend(input_xgboost_data(sub_data, time_label))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=60000, shuffle=False, drop_last=False)\n",
    "\n",
    "    data_iter = iter(train_loader)\n",
    "    train_data = next(data_iter)\n",
    "    X = train_data['in']\n",
    "    y = train_data['out']\n",
    "\n",
    "    test_iter = iter(test_loader)\n",
    "    test_data = next(test_iter)\n",
    "\n",
    "    # Create regression matrices\n",
    "    dtrain_reg = xgb.DMatrix(X, y)\n",
    "\n",
    "    X_test = test_data['in']\n",
    "    y_test = test_data['out']\n",
    "    dtest_reg = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "    params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\", \"device\": \"cuda\"}\n",
    "\n",
    "    print(X.shape, X_test.shape)\n",
    "    \n",
    "    n = 10\n",
    "    xgmodel = xgb.train(\n",
    "       params=params,\n",
    "       dtrain=dtrain_reg,\n",
    "       num_boost_round=n,\n",
    "    )\n",
    "\n",
    "    preds = xgmodel.predict(dtest_reg)\n",
    "    print(len(y_test[y_test>0]), len(preds[preds>0.1]), len(preds))\n",
    "    print('XgBoost: AUC = %.2f' % roc_auc_score(y_test, preds))  #1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b5536",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env, VecEnv\n",
    "\n",
    "# parallel env runs\n",
    "num_process = 50\n",
    "# survey window size (last \"window_size\" survey received points)\n",
    "window_size = 30\n",
    "\n",
    "\n",
    "# action encoding: \n",
    "# 0 - no survey or predict\n",
    "# 1 - yes survey or predict\n",
    "action_dim = 1\n",
    "action_max = 2\n",
    "\n",
    "# feature encoding: mean of survey items\n",
    "feature_dim = 14\n",
    "\n",
    "# y encoding\n",
    "# 0 - no lapse within 24hr\n",
    "# 1 - yes lapse within 24hr\n",
    "state_dim, embed_dim, y_max = 11, 128, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e88104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39658178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb11780",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9691a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env, VecEnv\n",
    "\n",
    "# parallel env runs\n",
    "num_process = 50\n",
    "# survey window size (last \"window_size\" survey received points)\n",
    "window_size = 30\n",
    "\n",
    "\n",
    "# action encoding: \n",
    "# 0 - no survey or predict\n",
    "# 1 - yes survey or predict\n",
    "action_dim = 1\n",
    "action_max = 2\n",
    "\n",
    "# feature encoding: mean of survey items\n",
    "feature_dim = 14\n",
    "\n",
    "# y encoding\n",
    "# 0 - no lapse within 24hr\n",
    "# 1 - yes lapse within 24hr\n",
    "state_dim, embed_dim, y_max = 11, 128, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get trajectory sample batch\n",
    "def get_sample(traj, model, device):\n",
    "    b1 = model(traj['prev_state'], traj['prev_action'], output_embedding=True).detach()\n",
    "    action = traj['action'].reshape(-1, 1).to(device)  # [B, n]\n",
    "    reward = traj['reward'].reshape(-1, 1).to(device)  # [B, n]\n",
    "    b2 = model(traj['next_state'], traj['next_action'], output_embedding=True).detach()\n",
    "    t1 = traj['ptype']['type']\n",
    "    t2 = traj['ntype']['type']\n",
    "    done = traj['done'].reshape(-1, 1).to(device)\n",
    "\n",
    "    return t1, b1, action, reward, t2, b2, done\n",
    "\n",
    "# train function (without extra features)\n",
    "def train(venv, model, agent, feature_optimizer, predict_buffer, max_iter = 50, freq=1, burn_in = 0, feature_weight = 0.1):\n",
    "    buffer = ReplayBuffer()\n",
    "    ce_criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    mse_criterion = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    for episode in range(max_iter):\n",
    "        obs, info = venv.reset(mode='train')\n",
    "\n",
    "        # initialize slideing window\n",
    "        ts = torch.zeros(num_process, 500, state_dim).to(device) \n",
    "        ta = torch.zeros(num_process, 500, action_dim).to(int).to(device) \n",
    "        weights = torch.zeros(num_process, 500, 1).to(device)\n",
    "        steps = torch.zeros(num_process, 1).to(int).to(device)\n",
    "        # initialize belief states\n",
    "        bf = model(ts, ta, output_embedding=True, steps=steps).detach()\n",
    "\n",
    "        # initialize buffers / debug variables\n",
    "        sample_traj = []\n",
    "        predict_samples = []\n",
    "        \n",
    "        measured_ta = []\n",
    "        measured_tr = []\n",
    "        cumr = []\n",
    "        \n",
    "        # generate trajectories\n",
    "        for t in range(1000):\n",
    "            p = random.random()\n",
    "            \n",
    "            # epsilon greedy\n",
    "            if( t < 5 or episode < burn_in ):\n",
    "                actions = torch.zeros(num_process,action_dim).to(int) + 1\n",
    "            elif( 0.45 < p and p < 0.5 ):\n",
    "                actions = torch.randint(low=0, high=action_max, size=(num_process,action_dim))\n",
    "            # burn-in data\n",
    "            else:\n",
    "                actions, _, _ = agent.select_action(bf, types)\n",
    "                actions = actions.detach().cpu()\n",
    "\n",
    "            obs, rewards, dones, infos = venv.step(actions)        \n",
    "            all_done = True\n",
    "            #predict_ys, _ = model.predict_forward(bf)            \n",
    "            #check_y = nn.Softmax(dim=-1)(predict_ys[11]).reshape(y_max).detach().cpu()                \n",
    "            \n",
    "            for i in range(num_process):\n",
    "                if( infos[i] == -1 ):\n",
    "                    continue\n",
    "                \n",
    "                all_done = False\n",
    "                # ptype = {'type': types[i], 'total_collect': old_cnt[i], 'recent_collect': rec_cnt[i]}\n",
    "                \n",
    "                if (infos[i]['type'] == 'survey'):\n",
    "                    ts[steps[i]] = obs[i].reshape(1,-1).to(device)\n",
    "                    ta[steps[i]] = (actions[i]%2).reshape(1,-1).to(device)\n",
    "                    steps[i] += 1\n",
    "\n",
    "                else:\n",
    "#                     if( i == 11 and (t+1) % 50 == 0 ):\n",
    "#                         print(pts[0], actions[i], check_y[1], infos[i]['out'], rewards[i])\n",
    "                    \n",
    "                    predict_samples.append({'action': pta, 'state': pts, 'out': infos[i]['out'], \\\n",
    "                                            'feature': infos[i]['feature']})\n",
    "\n",
    "#                 types[i] = 1 if( infos[i]['next_type'] == 'query' ) else 0\n",
    "#                 ntype = {'type': types[i], 'total_collect': old_cnt[i], 'recent_collect': rec_cnt[i]}\n",
    "#                 nts, nta = ts[i] + 0.0, ta[i] + 0\n",
    "\n",
    "                sample_traj.append({'ptype': ptype, 'prev_state': pts, 'prev_action': pta, \\\n",
    "                        'action': actions[i], 'reward': rewards[i], \\\n",
    "                        'ntype': ntype, 'next_action': nta, 'next_state': nts, 'done': dones[i]})\n",
    "\n",
    "                if(i==11):\n",
    "                    measured_tr.append(rewards[i].item())\n",
    "                    measured_ta.append(actions[i].item()%2)\n",
    "                    cumr.append(rewards[i])\n",
    "                    \n",
    "            if( all_done ): \n",
    "                break\n",
    "                \n",
    "            bf = model(ts, ta, output_embedding=True, steps=steps).detach()\n",
    "\n",
    "        # print('episode ', episode, '- reward average:', ta[11].transpose(0,1), sum(cumr), len(cumr) )#, measured_ta, measured_tr)\n",
    "        buffer.add_episodes(sample_traj)\n",
    "        predict_buffer.add_episodes(predict_samples)\n",
    "        \n",
    "        #######################################################\n",
    "        # Training Phase        \n",
    "        #######################################################\n",
    "        # 1. train prediction first\n",
    "        feat_train_loaders = predict_buffer.get_loader()\n",
    "        feat_data_iter = iter(feat_train_loaders)\n",
    "\n",
    "        for j in range(0, 200):\n",
    "            try:\n",
    "                traj = next(feat_data_iter)\n",
    "\n",
    "                refs = model(traj['state'], traj['action'])\n",
    "                out_ys, out_features = model.predict_forward(refs)\n",
    "                ys = traj['out'].to(device).reshape(-1)\n",
    "                features = traj['feature'].to(device).reshape(-1, feature_dim)\n",
    "\n",
    "                predict_loss = ce_criterion(out_ys, ys).mean()\n",
    "                # predict_loss += feature_weight * mse_criterion(out_features, features).mean()\n",
    "                predict_loss.backward()\n",
    "                \n",
    "                feature_optimizer.step()\n",
    "                feature_optimizer.zero_grad()\n",
    "\n",
    "            except StopIteration:\n",
    "                feat_train_loaders = predict_buffer.get_loader()\n",
    "                feat_data_iter = iter(feat_train_loaders)\n",
    "                continue\n",
    "        \n",
    "        print(predict_loss)\n",
    "        continue\n",
    "                        \n",
    "        # 2. then train q\n",
    "        train_loaders = buffer.get_loader()\n",
    "        data_iter = iter(train_loaders)\n",
    "\n",
    "        for j in range(0, 500):\n",
    "            try:\n",
    "                traj = next(data_iter)\n",
    "                batch = get_sample(traj, model, device)\n",
    "\n",
    "            except StopIteration:\n",
    "                train_loaders = buffer.get_loader()\n",
    "                data_iter = iter(train_loaders)\n",
    "                continue\n",
    "\n",
    "            agent.update(batch)\n",
    "\n",
    "        agent.update_target()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0e397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(venv, model, agent, mode='policy', run_id=0, kfold_id=0, penalty=-1., freq=1):\n",
    "    scatter = []\n",
    "    num_process = len(venv.test_ids)\n",
    "    \n",
    "    cnt, n_measure, n_hit = [0 for i in range(num_process)], [0 for i in range(num_process)], [0 for i in range(num_process)]\n",
    "    y, outy = [], []\n",
    "\n",
    "    obs, info = venv.reset(mode='test')\n",
    "    \n",
    "    ts = torch.zeros(num_process, window_size, state_dim).to(device)\n",
    "    types = torch.zeros(num_process).to(device)\n",
    "    ta = torch.zeros(num_process, window_size, action_dim).to(int).to(device)\n",
    "    old_cnt = [0 for t in range(num_process)]\n",
    "    rec_cnt = [0 for t in range(num_process)]\n",
    "\n",
    "    bf = model(ts, ta, output_embedding=True).detach()    \n",
    "    for t in range(1000):\n",
    "#         if( mode == 'policy' ):\n",
    "#             actions, _, _ = agent.select_action(bf, types)\n",
    "#             actions = actions.detach().cpu()\n",
    "#         else:\n",
    "\n",
    "        p = random.random()\n",
    "        actions = torch.zeros(num_process, action_dim).to(int)\n",
    "        if( p < 1. / freq ):\n",
    "            actions = actions + 1\n",
    "            \n",
    "        obs, rewards, dones, infos = venv.step(actions)\n",
    "        predict_ys, _ = model.predict_forward(bf)\n",
    "        predict_ys = predict_ys.detach()\n",
    "   \n",
    "        # add transition data to dataset\n",
    "        all_done = True\n",
    "        for i in range(num_process):\n",
    "            if( infos[i] == -1 ):\n",
    "                continue\n",
    "\n",
    "            all_done = False\n",
    "            if (infos[i]['type'] == 'query'):\n",
    "                check_y = nn.Softmax(dim=-1)(predict_ys[i]).reshape(y_max).detach().cpu()                \n",
    "                y.append(infos[i]['out'])\n",
    "                outy.append(check_y[1])\n",
    "                \n",
    "            else:\n",
    "                ts[i] = torch.cat([ts[i][1:], obs[i].reshape(1,-1).to(device)], dim=0)\n",
    "                ta[i] = torch.cat([ta[i][1:], (actions[i]%2).reshape(1,-1).to(device)], dim=0)\n",
    "                \n",
    "                cnt[i] += 1\n",
    "                n_measure[i] += 1 if( actions[i] % 2 == 1 ) else 0\n",
    "                n_hit[i] += 1 if( obs[i,0] > 0 ) else 0\n",
    "\n",
    "            types[i] = 1 if( infos[i]['next_type'] == 'query' ) else 0\n",
    "\n",
    "        if( all_done ): \n",
    "            break\n",
    "                \n",
    "        bf = model(ts, ta, output_embedding=True).detach()\n",
    "\n",
    "    for i in range(num_process):\n",
    "        scatter.append([n_measure[i]/cnt[i], n_hit[i]/cnt[i]])\n",
    "        print(venv.test_ids[i], ':', n_measure[i], n_hit[i], cnt[i])\n",
    "    \n",
    "    path = os.path.join(\"./results\", f\"run_{run_id}_kfold_{kfold_id}_penalty_{penalty}.pt\")\n",
    "    things_to_save = {\n",
    "        'test_ids': venv.test_ids,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'agent_state_dict': agent.save_dict()\n",
    "    }\n",
    "    torch.save(things_to_save, path)\n",
    "    \n",
    "    scatter = np.array(scatter)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(4, 3))  \n",
    "\n",
    "    plt.scatter(scatter[:,1], scatter[:,0])\n",
    "    plt.xlabel(\"Average Lapse Count\")\n",
    "    plt.ylabel(\"Survey Ratio\")\n",
    "    plt.show()\n",
    "\n",
    "    print('Average Survey Ratio:', np.mean(scatter[:,0]))\n",
    "\n",
    "    import xgboost as xgb\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    print('AUC = %.2f' % roc_auc_score(y, outy))  #1\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68a158",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from SACD import init_SACD_agent\n",
    "from model import build_model\n",
    "from buffer import ReplayBuffer\n",
    "  \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# weight-decay params: {1e-3, 5e-4, 1e-4, 5e-5, 1e-5}\n",
    "\n",
    "def k_fold_test(k=5, run_id=0):\n",
    "    shuffled_index = list(range(151))\n",
    "    random.shuffle(shuffled_index)\n",
    "\n",
    "    for i in range(k):\n",
    "        st,et = i*151//k, (i+1)*151//k\n",
    "\n",
    "        test_index = shuffled_index[st:et]\n",
    "        train_index = list(set(range(151)) - set(test_index))\n",
    "        xgboost_main(train_index, test_index)\n",
    "        venv = VecEnv(env_list, train_index, test_index)\n",
    "        \n",
    "        model = build_model(embed_dim, state_dim, action_dim, feature_dim, action_max, \\\n",
    "                            y_max, model_family='gpt2').to(device)\n",
    "        agent = init_SACD_agent(embed_dim, action_dim, action_max, device, weight_decay=1e-4, \\\n",
    "                                lr_actor=1e-4, lr_critic=2e-4, entropy_regularizer=0.03)\n",
    "        feature_optimizer = torch.optim.Adam([{'params': model.parameters(), 'lr': 5e-5, 'weight_decay': 3e-4}])\n",
    "        predict_buffer = ReplayBuffer()\n",
    "\n",
    "        # init predictor part\n",
    "        venv.set_probe_penalty(0.01)\n",
    "        train(venv, model, agent, feature_optimizer, predict_buffer, max_iter=30)\n",
    "        # Test full observation-prediction\n",
    "        test(venv, model, agent, 'full', run_id=run_id, kfold_id=i, penalty=-1)\n",
    "\n",
    "        penalty=0.05\n",
    "        for freq in [2,4,10,20]:\n",
    "            venv.set_probe_penalty(penalty)\n",
    "            train(venv, model, agent, feature_optimizer, predict_buffer, max_iter=20, freq=freq)\n",
    "            test(venv, model, agent, run_id=run_id, kfold_id=i, penalty=penalty, freq=freq)\n",
    "\n",
    "        print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d13243",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_test(5, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
